# -*- coding: utf-8 -*-
"""what  a waste9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yVGkx9yck1i89dSgo6WSaWrKD8w1kKL3
"""

# Load datasets
import pandas as pd
city_data = pd.read_csv("data/city_level_data_0_0.csv", encoding='cp1252')
# Added encoding='latin-1' to handle the different file encoding
city_codebook = pd.read_csv("data/city_level_codebook_0.csv", encoding='latin-1')
city_data

print(city_data.isnull().sum())

city_Newdata = city_data[["iso3c","region_id","country_name","city_name","income_id","population_population_number_of_people","total_msw_total_msw_generated_tons_year"]].drop_duplicates()
# This will correctly select the desired columns and create a copy in city_Newdata
# Check for missing values
print(city_Newdata.isnull().sum())

city_total_data = city_Newdata.dropna(subset=["total_msw_total_msw_generated_tons_year"], inplace=False)
# This will drop rows where "total_msw_total_msw_generated_tons_year" has missing values
# Check for missing values
print(city_total_data.isnull().sum())

city_total_data["total_msw_total_msw_generated_tons_year"] = pd.to_numeric(city_total_data["total_msw_total_msw_generated_tons_year"], errors='coerce')
city_total_data["population_population_number_of_people"] = pd.to_numeric(city_total_data["population_population_number_of_people"], errors='coerce')
city_total_data["msw per capita"] = city_total_data["total_msw_total_msw_generated_tons_year"] / city_total_data["population_population_number_of_people"]
city_total_data

city_Newcodebook = city_codebook.iloc[:,0:8]
city_Year_codebook = city_Newcodebook.dropna(subset=["year"])
tonnes_data = city_Year_codebook[city_Year_codebook['units'] == 'tonnes/year']
city_Year_codebook['year'] = city_Year_codebook['year'].astype(int)
tonnes_data

import pandas as pd

# Example: Rename columns in `tonnes_data` to match `city_com_data`
tonnes_data.rename(columns={
    "regionID": "region_id",
    "incomeID": "income_id"
}, inplace=True)

# Perform the merge on common columns
merged_data = pd.merge(
    city_total_data,
    tonnes_data[["city_name", "year"]],  # Only keep necessary columns from tonnes_data
    how="left",  # Left join to keep all rows from city_com_data
    on="city_name"  # Merge on city_name
)

# Drop rows with missing 'year'
city_com = merged_data.dropna(subset=["year","total_msw_total_msw_generated_tons_year"],inplace=False)
# Drop rows where "year" is NaN
city_com_codebook = city_com.dropna(subset=["year"])
# Convert the "year" column to integers
city_com_codebook['year'] = city_com_codebook['year'].astype(int)
city_com_codebook

import plotly.express as px

# Filter data for LIC and HIC only
filtered_data = city_com_codebook[city_com_codebook['income_id'].isin(['LIC', 'HIC'])]

# Create the bar plot
fig = px.bar(
    filtered_data,
    x='country_name',
    y='msw per capita',
    color='income_id',
    title='Comparison of waste generated per capita in Low income cities vs. High income cities',
    barmode='group'  # Grouped bars for side-by-side comparison
)

# Show the plot
fig.show()

import plotly.express as px
import matplotlib.pyplot as plt

# Trend analysis for a specific metric
yearly_trend = city_com_codebook.groupby('year')['msw per capita'].mean()
yearly_trend.plot()
plt.title('waste generated per capita in cities Trends Over Time')
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Define the list of  countries
India_cities = ["India"]

# Filter the city-level data for these countries
India_cities_data = city_com_codebook[city_com_codebook["country_name"].isin(India_cities)]

# Calculate waste management efficiency (inverse of MSW per capita)
# To avoid division by zero or extremely high values due to small numbers, add a small constant to MSW per capita
India_cities_data['efficiency'] = 1 / (India_cities_data['msw per capita'] + 1e-9)

# Investigate top and bottom cities based on efficiency
top_cities = India_cities_data.nlargest(5, 'efficiency')[['city_name', 'msw per capita', 'efficiency']]
bottom_cities = India_cities_data.nsmallest(5, 'efficiency')[['city_name', 'msw per capita', 'efficiency']]

# Print top and bottom cities
print("Top 5 Cities with Highest Waste Management Efficiency:")
print(top_cities)
print("\nBottom 5 Cities with Lowest Waste Management Efficiency:")
print(bottom_cities)

# Visualize waste management efficiency
plt.figure(figsize=(12, 6))
plt.bar(India_cities_data['city_name'], India_cities_data['efficiency'], color='skyblue')
plt.title("Waste Management Efficiency Across Cities in India", fontsize=14)
plt.xlabel("City Name", fontsize=12)
plt.ylabel("Efficiency (1 / MSW per capita)", fontsize=12)
plt.xticks(rotation=90, fontsize=10)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

# Summary statistics
efficiency_summary = India_cities_data['efficiency'].describe()
print("\nSummary Statistics for Waste Management Efficiency:")
print(efficiency_summary)